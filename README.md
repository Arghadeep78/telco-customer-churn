
# Telco Customer Churn Prediction üìûüìâ

This project builds an end-to-end machine learning pipeline to predict customer churn using a real-world telecom dataset. It includes data exploration, preprocessing, model tuning, and ensemble learning.

## üìå Objective

Predict whether a customer is likely to discontinue service based on their subscription and usage data. The goal is to help telecom companies retain customers through early churn detection.

---

## üß† Project Highlights

- üìä Exploratory Data Analysis (EDA)
- üßπ Data Cleaning and Feature Engineering
- üîç Feature Encoding and Scaling
- üß™ Hyperparameter tuning with **Optuna**
- ‚öñÔ∏è Class balancing with **RandomOverSampler**
- ü§ñ Ensemble learning using a **Stacking Classifier**
- üìà Evaluation with ROC-AUC, F1, Precision, Recall, Confusion Matrix

---

## üìÅ Repository Structure

```
telco-customer-churn/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_final_analysis.ipynb       # EDA and insights
‚îÇ   ‚îî‚îÄ‚îÄ 02_modeling_pipeline.ipynb    # Modeling and evaluation
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## ‚öôÔ∏è Tech Stack

- Python
- Jupyter Notebook
- pandas, numpy, seaborn, matplotlib
- scikit-learn, xgboost
- imbalanced-learn, optuna, tqdm

---

## üöÄ How to Run

1. **Clone the repository**

```bash
git clone https://github.com/Arghadeep78/telco-customer-churn.git
cd telco-customer-churn
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Launch the notebooks**

```bash
jupyter notebook
```

---

## üìà Model Summary

The final model is a **Stacking Ensemble** combining:

- K-Nearest Neighbors
- Support Vector Classifier
- Random Forest
- Logistic Regression
- XGBoost

It is tuned using cross-validation and evaluated with ROC-AUC and F1 score.

---

## üì¨ Contact

Created by **[Arghadeep Ghosh]**  
üîó [LinkedIn](https://www.linkedin.com/in/arghadeep-ghosh-895b27287/)  
üì´ [Email](arghadeepghosh17@gmail.com)

---

> ‚≠ê Star this repo if you like the project or find it helpful!
